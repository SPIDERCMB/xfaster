{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is also a Jupyter notebook, which can be found in [the example notebooks directory](https://github.com/SPIDERCMB/xfaster/tree/main/example/notebooks). If you're running the notebook, rather than looking at the documentation produced from it, the links will not work. [Look at the docs for working links](https://spidercmb.github.io/xfaster/notebooks/XFaster_Tutorial.html).\n",
    "\n",
    "The notebook reads intermediate output npz files from disk. To instead run the pieces starting from maps, first generate the example maps by running the script `xfaster/example/make_example_maps.py`, and set the checkpoint to something other than `None`.  This script generates sample signal (CMB), noise and foreground ensembles for the two SPIDER frequency bands, as well as two sets of simulated data maps (one with signal, noise and foreground components; and one with just signal and noise components)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main ingredients of the XFaster code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get into the functions that produce each of the components that gets fed into the equations for bandpower deviations, $q_b$ and the Fisher matrix (Equations 17 and 18 in the [Algorithm section](../algorithm.rst)), let's first talk about how XFaster is structured and what it expects as inputs.\n",
    "\n",
    "There are two main python modules in XFaster: [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec) and [xfaster_class.py](../api.rst#module-xfaster.xfaster_class). [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec) contains two main functions: [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) and [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit). [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) calls all of the functions to make XFaster happen (all located in [xfaster_class.py](../api.rst#module-xfaster.xfaster_class)) in the order they need to happen. [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit) takes arguments for submitting the job to a queue. XFaster is not highly parallelized. However, significant speed-up is gained from using more cores in the simulation pseudo-spectrum calculation through under-the-hood use of OMP. Therefore, if you're starting from a checkpoint after \"sims\", no significant speed-up will be gained when using more cores. \n",
    "\n",
    "There are a few other modules you might interact with: \n",
    "\n",
    "* [parse_tools.py](../api.rst#module-xfaster.parse_tools): contains a bunch of tools for converting between data structures, especially between dictionaries and matrices\n",
    "* [spec_tools.py](../api.rst#module-xfaster.spec_tools): contains functions for generating and manipulating model power spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying what data to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top level module you interact with is [xfaster_exec.py](../api.rst#module-xfaster.xfaster_exec), which takes your arguments, and has some reasonable defaults for any you don't provide. In addition to arguments, you must point the code to the inputs you want to run on. The first of these inputs is maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps\n",
    "\n",
    "The main inputs to the code are maps-- data maps, signal and noise simulations, and masks. Rather than pointing to each map individually, there is a directory structure that the code expects. Its contents look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <data_root>/\n",
    "    ├── data_<data_type>\n",
    "    │   ├── <data_subset1>\n",
    "    │   │   ├── map_<tag1>.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>.fits\n",
    "    │   ├── <data_subset2> (same filenames as <data_subset1>)\n",
    "    │   ├── ....\n",
    "    │   ├── <data_subsetM>\n",
    "    ├── signal_<signal_type>\n",
    "    │   ├── spec_signal_<signal_type>.dat\n",
    "    │   ├── <data_subset1>\n",
    "    │   │   ├── map_<tag1>_0000.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tag1>_####.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>_0000.fits\n",
    "    │   │   ├── ...\n",
    "    │   │   ├── map_<tagN>_####.fits\n",
    "    │   ├── ....\n",
    "    │   ├── <data_subsetM> (same filenames as <data_subset1>)\n",
    "    ├── noise_<noise_type> (same filenames as signal_<signal_type>)\n",
    "    ├── masks_<mask_type>\n",
    "    │   ├── mask_map_<tag1>.fits\n",
    "    │   ├── ...\n",
    "    │   ├── mask_map_<tagN>.fits\n",
    "    [[optional:]]\n",
    "    ├── foreground_<foreground_type_sim> (same filenames as signal_<signal_type>)\n",
    "    ├── templates_<template_type>\n",
    "    │   ├── template1 (same filenames as data_<data_type>)\n",
    "    │   ├── template2 (same filenames as data_<data_type>)\n",
    "    └── reference_<reference_type>\n",
    "        ├── reference1 (same filenames as data_<data_type>)\n",
    "        └── reference2 (same filenames as data_<data_type>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of `data`, `signal`, `noise`, and `mask` has a top level directory with a preordained, fixed prefix (`data`, `signal`, `noise`, `mask`) and then some suffix specified by the user which is appended with an underscore. So, for example, to run XFaster on the example set of maps, I need to specify in my arguments: `data_type=raw`, `signal_type=synfast`, `noise_type=gaussian`, `mask_type=rectangle`.\n",
    "\n",
    "All maps must be HEALPIX fits files. Data maps must be named `map_<tag>.fits`; simulated signal and noise maps must be named `map_<tag>_####.fits`, where #### is any length numerical tag indicating a sim realization; and masks are labeled `mask_map_<tag>.fits`.\n",
    "\n",
    "If using `pol=True`, masks must be 3 x Npix I,Q,U maps. You can use a different mask for intensity and polarization, in which case your mask must be 2 x Npix, where the first row is used for T and the second for P.\n",
    "\n",
    "To indicate which maps you want, pass the argument `data_subset` a glob-parseable path relative to the top level data directory-- in this case, `data_raw`. [Glob](https://docs.python.org/3/library/glob.html) works just like the unix shell does for matching file paths, so it is easy to test in advance which maps you're going to get. Just do `ls <path_to_data_maps>/full/*150*` and check that all the maps you want to use are listed. Then, you should set `data_subset` to `full/*150*`, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all implemented in `_get_data_files()` (called by [get_files()](../api.rst#xfaster.xfaster_class.XFaster.get_files)) like so:\n",
    "```python\n",
    "\n",
    "\n",
    "# find all map files                                                               \n",
    "map_root = os.path.join(data_root, \"data_{}\".format(data_type))\n",
    "map_files = []\n",
    "data_subset = data_subset.split(\",\")\n",
    "for f in np.atleast_1d(data_subset):\n",
    "    files = glob.glob(os.path.join(map_root, \"{}.fits\".format(f)))\n",
    "    if not len(files):\n",
    "        raise OSError(\"Missing files in data subset {}\".format(f))\n",
    "    map_files.extend(files)\n",
    "data_subset = \",\".join(data_subset)\n",
    "map_files = sorted(map_files)\n",
    "map_files = [f for f in map_files if os.path.basename(f).startswith(\"map_\")]\n",
    "map_tags = [\n",
    "    os.path.splitext(os.path.basename(f))[0].split(\"_\", 1)[1] for f in map_files\n",
    "]\n",
    "\n",
    "```\n",
    "So you've specified which data maps you want to compute power spectra for. To get the corresponding sim maps, the code takes whatever data maps were found matching data_subset, and tries to match those to maps in the sims directory, with the only difference the sim index tag. Here's what that looks like in the function `_get_sim_files()`:\n",
    "```python\n",
    "# find all corresponding sims\n",
    "# for example, when called for signal sims:\n",
    "#     _get_sim_files(\n",
    "#         name=\"signal\",\n",
    "#         root=\"signal_{}\".format(signal_type),\n",
    "#         subset=signal_subset,\n",
    "#     )\n",
    "root = os.path.join(data_root, root)\n",
    "num_files = None\n",
    "all_files = []\n",
    "for f in map_files:\n",
    "    files = sorted(\n",
    "        glob.glob(\n",
    "            f.replace(map_root, root).replace(\n",
    "                \".fits\", \"_{}.fits\".format(subset)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    nfiles = len(files)\n",
    "    if not nfiles:\n",
    "        raise OSError(\"Missing {} sims for {}\".format(name, f))\n",
    "    ...\n",
    "    all_files.append(files)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's easy to get errors at the reading files step. XFaster requires that all your maps have the same number of sims, though you are allowed to have a different from of signal and noise sims. If you do not want to use the full set of signal and noise maps in a directory, if you can set the `signal_subset` and `noise_subset` arguments, which default to `'*'`. This glob-parseable tag is applied to the `####` sim index tag. So, if I have a set of sims, eg, `map_95_0000.fits`-`map_95_0099.fits`, as in the example, but for some reason I only want to use the first 50, I can set `signal_subset='00[0-4]*`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other inputs\n",
    "\n",
    "In addition to maps, the code also requires a config file. This tells the code everything else it needs to know about your data. Here's the config file for the example:\n",
    "\n",
    "```python\n",
    "\n",
    "# Band centers in GHz (needed for foreground fitting) for each map tag.                    \n",
    "# Tags listed here should be a superset of tags that may be included in a run.             \n",
    "[frequencies]\n",
    "95 = 94.7\n",
    "150 = 151.0\n",
    "\n",
    "# A numpy dictionary containing Bl for each map tag.                                       \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should have a fwhm listed below.                                            \n",
    "# The value for each key should be a numpy array of dimensions (3, lmax + 1),              \n",
    "# for TT, TP and PP beam windows.                                                          \n",
    "[beam]\n",
    "beam_product = None\n",
    "beam_error_product = None\n",
    "\n",
    "# FHWM in arcmin for each map tag, if using Gaussian beam model.                           \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should be in the beam product file.                                         \n",
    "[fwhm]\n",
    "95 = 41\n",
    "150 = 29\n",
    "\n",
    "# Fractional error on the FWHM for each map tag, if using a Gaussian beam model.           \n",
    "# Keys should match those in freqs.                                                        \n",
    "# Missing keys should be in the beam product file.                                         \n",
    "[fwhm_err]\n",
    "95 = 0.001\n",
    "150 = 0.001\n",
    "\n",
    "# Whether to compute transfer function qb parameters for each map tag.                     \n",
    "# Keys should match those in freqs.                                                        \n",
    "[transfer]\n",
    "95 = true\n",
    "150 = true\n",
    "```\n",
    "\n",
    "This is the full list of options that can be specified in the config file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step through the functions called in xfaster_exec\n",
    "### Setup and checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll proceed to stepping through each function in [xfaster_exec](../api.rst#module-xfaster.xfaster_exec). You'll never run the code this way--you'll just call [xfaster_run](../api.rst#xfaster.xfaster_exec.xfaster_run) or [xfaster_submit](../api.rst#xfaster.xfaster_exec.xfaster_submit) with the arguments that then get passed to these functions. But we'll do it this way so we can illustrate some of the intermediate data products as we go.\n",
    "\n",
    "This tutorial will follow the example script in [xfaster/example](https://github.com/SPIDERCMB/xfaster/tree/main/example). Note however that becasue maps are not stored in the repository, this notebook is instead reading from the intermediate files written to disk. \n",
    "\n",
    "First, we'll import XFaster and initialize our XFaster class with some arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xfaster as xf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, colormaps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xf.XFaster(config=\"../../example/config_example.ini\", output_root=\"../../example/outputs_example\", verbose=\"info\",\n",
    "              output_tag=\"95x150\", checkpoint=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the start of an XFaster run, you can specify at what checkpoint to start. The checkpoints are:\n",
    "```python\n",
    "checkpoints = [\n",
    "\t\"files\", # find all the map files\n",
    "\t\"masks\", # load in masks and compute their pseudo-spectra\n",
    "\t\"kernels\", # compute mask mode-coupling kernels\n",
    "\t\"sims_transfer\", # compute pseudo-spectra for signal sims used for computing the transfer function\n",
    "\t\"shape_transfer\", # load in the model spectrum for the transfer function\n",
    "\t\"transfer\", # compute the transfer function\n",
    "\t\"sims\", # compute pseudo-spectra for noise sims and signal sims if they're different from those used for the transfer function\n",
    "    \"beams\", # load in the beam window functions, and apply a pixel window function if pixwin=True\n",
    "    \"data\", # compute the pseudo-spectra of the data maps\n",
    "    \"template_noise\", # compute the pseudo-spectra of template noise simulations, if using Planck dust templates\n",
    "    \"shape\", # load in the model spectrum for bandpower computation\n",
    "\t\"bandpowers\", # do the Fisher iteration to compute bandpowers\n",
    "\t\"beam_errors\", # start the likelihood over including beam error parameterization\n",
    "\t\"likelihood\", # compute the parameter likelihoods\n",
    "]\n",
    "```\n",
    "\n",
    "Note that there are options to use different signal simulations for computing the transfer function and for computing other signal terms. This is mainly useful for null tests, as that's the only mode in which signal sims are used for anything other than transfer functions (to compute the expected signal residual that is subtracted from the data pseudo-spectra). If the signal simulations lack sufficient power (eg., for BB), the transfer function may not converge due to lack of measurable power. This is not a problem unique to XFaster, and this option allows the user more flexibility in the choice of sims used for different parts of the algorithm.\n",
    "\n",
    "Most of the time, `checkpoint` can be set to None, which starts the code from the last checkpoint completed (ie, it successfully wrote its intermediate data to disk). However, if you've made changes to the code or inputs, you may wish to force the code to start from an earlier checkpoint. It will then run that checkpoint and every one after it in the checkpoint tree (given near the top of [the XFaster class](../api.rst#xfaster.xfaster_class.XFaster))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function called after initializing the XFaster class is [get_files()](../api.rst#xfaster.xfaster_class.XFaster.get_files). This finds all of the raw data files in the data root that match the data subset criteria and constructs the map dimensions of the estimator.  All other file type arguments (`mask_type`, `signal_type`, `noise_type`, etc) must include files that match the set of map names found here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_opts = {\n",
    "    \"data_root\": \"../../example/maps_example\",\n",
    "    \"data_subset\": \"full/*95,full/*150\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars = X.get_files(**file_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`file_vars` is a dictionary returned by `get_files` that is also written to disk to finish the checkpoint. For example, all of the files found using your glob-parseable file tags are stored here, so you can see exactly what maps are being used for data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_vars['map_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_bin_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run [get_bin_def()](../api.rst#xfaster.xfaster_class.XFaster.get_bin_def) set up a dictionary that tells where the edges of the CMB bins are for each spectrum. We can also choose whether to fit for noise residuals or foregrounds, which we can set to have different bin widths than the CMB bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = X.get_bin_def(bin_width=25, lmin=2, lmax=500, tbeb=True, foreground_fit=False, \n",
    "                   residual_fit=True, bin_width_res=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd['cmb_tt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary has a key for each type of spectrum that will be fit, each of which stores the bin edges used for that spectrum fit. Each of these bin edge pairs represents a separate bandpower deviation ($q_b$) that will be fit.\n",
    "\n",
    "Residuals are fit per map, and by default are fit only for EE and BB, which are constrained to have the same fit parameter. To change this, use the option `res_specs`, which takes a list of the spectra you want to fit residuals for, ie. `[\"TT\", \"EE\", \"BB\"]` if you'd like to fit all of the spectra separately.\n",
    "\n",
    "Another option you might wish to use is `weighted_bins`, which changes the default $\\chi_b(\\ell)$ binning operator from a tophat to one that weights by $\\ell(\\ell+1)$.\n",
    "\n",
    "To enable fitting for a foreground component in the harmonic domain, set `foreground_fit=True`, and use the corresponding `bin_width_fg` to set the bin width for the foreground amplitude bins, and set `lmin_fg` and `lmax_fg` to optionally limit the bandwidth over which foregrounds are to be fit.  Optionally, also set `beta_fit=True` to enable fitting for a frequency spectral index component for the foreground amplitude; otherwise, the frequency dependence is assumed to follow a single component dust model as defined in [scale_dust()](../api.rst#xfaster.spec_tools.scale_dust).  If `foreground_fit` is True, the foreground model is assumed to be a simple power law model, as defined in [dust_model()](../api.rst#xfaster.spec_tools.dust_model), with the same transfer function as the CMB component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_mask_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now finished all the set-up. Now it's time to start calculating things. First, we compute the cross spectra of our masks--which will be needed for computing the $K_{\\ell \\ell^{\\prime}}$ mode-coupling matrix--and the $g_\\ell$ mode-counting factor. This is done with [get_mask_weights()](../api.rst#xfaster.xfaster_class.XFaster.get_mask_weights).\n",
    "\n",
    "For the example, we will not apply an empirical correction to $g_\\ell$, the calibration of which is discussed in Section 2.3.2 of the [XFaster paper](https://arxiv.org/abs/2104.01172).  Otherwise, we would set `apply_gcorr=True`, and the code would look in the masks directory for this correction file for each map. The `reload_gcorr` option is only useful when doing the empirical calibration; it reloads the file, while by-passing the checkpoint tree that is usually performed after `get_mask_weights`.  Instructions are [provided](../gcorr.rst) for constructing this calibration using the example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_stuff = X.get_mask_weights(mask_type=\"rectangle\", apply_gcorr=False, reload_gcorr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_stuff.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`w1`, `w2`, and `w4` are the first, second, and fourth moments of the mask. `fsky` is the fraction of sky the mask covers. These are needed for computing the $g_\\ell$ mode-counting term, labeled `gmat` in the outputs. `gmat` includes the $2\\ell+1$ factor and a correction factor, if desired.\n",
    "\n",
    "`wls`, contains the cross spectra of all the masks. For this and all other pseudo-spectra, the spectrum is computed just as `map2alm`, and then `alm2cl` healpy routines on the maps. If you're doing a polarized spectrum, you'll get three elements, (intensity, pol, intensity x pol). Since our intensity and pol masks are the same, all three elements are the same, and look like this (plotted as $D_\\ell$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = np.arange(501)\n",
    "lfac = ell * (ell+1) / (2*np.pi)\n",
    "plt.plot(lfac * w_stuff['wls']['150:150'][0])\n",
    "plt.ylabel(r'$\\frac{\\ell(\\ell+1)}{2\\pi}w_\\ell$')\n",
    "plt.xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** most of the quantities in XFaster are ordered dictionaries with the following nested structure:\n",
    "1. Spectra (either plain ['tt', 'ee'], etc, or ['cmb_tt', 'cmb_ee', ..., 'fg_tt', 'fg_ee', ..., 'res_tt', ...]\n",
    "2. Map/map cross. Crosses are indicated with a colon and are in alphabetical order (so 95 comes after 150, for example): ['150:150', '150:95', '95:95']\n",
    "3. Stuff. Typically an array, though depending on the data structure, it could be a more deeply nested dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to compute the kernels for each mask auto and cross spectrum using the function [get_kernels()](../api.rst#xfaster.xfaster_class.XFaster.get_kernels).  In the MASTER formalism, the kernel couples modes to each other on the sky due to the finite dimensions of the mask that is applied to each map that goes into computing a cross spectrum.  That is to say, the measured power at a particular $\\ell$ is a weighted average over several other neighboring modes $\\ell^\\prime$, and $K_{\\ell\\ell^\\prime}$ is the matrix that applies this weighting.\n",
    "\n",
    "The kernels are computed from the power spectrum of the mask, computed in the previous step.\n",
    "\n",
    "Let's plot some of these up.  Because we are using the same mask for all maps, the kernels for each map pair will look identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = X.get_kernels()\n",
    "print(k.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(12,5.5))\n",
    "m = ax[0,0].imshow(k['kern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[0,0].set_title('kern')\n",
    "ax[0,0].set_ylabel(r'$\\ell$')\n",
    "ax[0,1].imshow(k['pkern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[0,1].set_title('pkern')\n",
    "ax[1,0].imshow(k['mkern']['150:150'], norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[1,0].set_title('mkern')\n",
    "ax[1,0].set_ylabel(r'$\\ell$')\n",
    "ax[1,0].set_xlabel(r'$\\ell^\\prime$')\n",
    "ax[1,1].imshow(np.abs(k['xkern']['150:150']), norm=colors.LogNorm(vmax=0.01, vmin=1e-10))\n",
    "ax[1,1].set_title('xkern')\n",
    "ax[1,1].set_xlabel(r'$\\ell^\\prime$')\n",
    "fig.colorbar(m, ax=ax.ravel().tolist());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the shorter dimension ($\\ell$) of each kernel goes up to $\\ell_{max}$, and the longer dimension ($\\ell^\\prime$) extends to $2 \\ell_{max} + 1$.  The kernels are apodized, so that for any row $\\ell$, the kernels are zero for values $\\ell^\\prime > \\ell + \\ell_{max}$.  The longer dimension is summed over in computing the $\\tilde{\\mathcal{C}}_{b\\ell}$ terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get the ensemble average of all of our signal and noise simulations, which we're going to use to calculate the filter transfer function and the noise shape, respectively. This is done with [get_masked_sims()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_sims). The method will also compute the signal cross noise terms, which are used for null tests, where they can contribute significantly to the expected residuals that are subtracted from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is doing a very simple thing. For each pair of maps of a given sim index, it \n",
    "\n",
    "1. Applies the mask.\n",
    "2. Transforms the maps into $a_{\\ell m}$s using the healpy routine `map2alm`.\n",
    "3. Transforms those into $\\tilde{\\mathcal{C}}_\\ell$s for that pair using the healpy routine `alm2cl`.\n",
    "4. Adds the $\\tilde{\\mathcal{C}}_\\ell$s to a running average for that particular map cross and spectrum.\n",
    "\n",
    "It only does `map2alm` once per map and caches the result for use in other cross spectra since this is the slowest step in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = X.get_masked_sims(signal_type=\"synfast\", noise_type=\"gaussian\")\n",
    "print(sims.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting outputs are:\n",
    "\n",
    "* `cls_signal`: the average of the signal-only cross spectra, used to compute the transfer function\n",
    "* `cls_noise`: the average of the noise-only cross spectra, used as the noise model, $N_\\ell$\n",
    "* `cls_sim`: the average of the signal+noise spectra, where signal and noise maps are added in $a_{\\ell m}$s and thus the spectra include SxN terms.\n",
    "* `cls_med`: the median of the signal+noise spectra-- this is mainly used for debugging potential biases seen in the pipeline\n",
    "\n",
    "The rest of the spectra are not symmetrized. For all previously listed spectra, the result is the average of map i x map j and map j x map i, which matters for off-diagonal spectra: TE, TB, EB. Below, we preserve the individual cross spectra as they are needed for the null test model. In this model, at each Fisher iteration, the noise residual fit (per map and per residual spectrum type) is then used to adjust the expectation spectrum subtracted from the data. The expectation spectrum subtracted from, eg, map 1 T x map 2 E is $S_1^T\\times S_2^E + S_1^T \\times N_2^E + N_1^T \\times S_2^E + N_1^T \\times N_2^E$. Each of the last three terms is subject to misestimation of $N$, so we account for that by scaling the following terms by the appropriate noise residual fit.\n",
    "\n",
    "* `cls_res[\"nxn0\"]`: the average spectrum for noise i x noise j\n",
    "* `cls_res[\"nxn1\"]`: the average spectrum for noise j x noise i\n",
    "* `cls_res[\"sxn0\"]`: the average spectrum of signal i x noise j\n",
    "* `cls_res[\"sxn1\"]`: the average spectrum of noise j x signal i\n",
    "* `cls_res[\"nxs0\"]`: the average spectrum of noise i x signal j\n",
    "* `cls_res[\"nxs1\"]`: the average spectrum of signal j x noise i\n",
    "\n",
    "\n",
    "These spectra have all the effects of the masking, filtering, and beam (for signal sims) included. Let's compare a couple of them to get a sense for what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * sims['cls_signal']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * sims['cls_signal']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the same idealized transfer function to make both 95 and 150 GHz maps, so their low-$\\ell$ signal is similar. However, for 150 GHz we use a 29 arcmin beam, and for 95 GHz, we use a broader 41 arcmin beam. The difference is evident at high $\\ell$, where the 150 GHz signal spectra recover more power.\n",
    "\n",
    "Similarly, we can plot up the noise averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * sims['cls_noise']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * sims['cls_noise']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In making the example maps, we have set the noise amplitude to be a bit higher for 95 GHz, which is evident in the noise auto-spectra. As expected, the cross-spectra is uncorrelated and mean-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_beams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next component we need for our equations is the beam window function, $B_\\ell$, done with [get_beams()](../api.rst#xfaster.xfaster_class.XFaster.get_beams). XFaster does not solve for this-- you have to tell it what it is. You do this in your config.ini file. You can either specify Gaussian FWHM values (in arcmin) for each map tag, or specify a `.npz` file that contains a dictionary of $B_\\ell$ vectors per map tag. You can mix and match these as well-- the code will first look for the tags in the dictionary file, and if it doesn't find the tag there, it will look for a FWHM field for that tag.\n",
    "\n",
    "The only additional option available is `pixwin`, which is default True. This applies an additional pixel window function to your beam window function, corresponding to the $N_{side}$ of the input maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beams = X.get_beams(pixwin=True)\n",
    "print(beams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have a different beam for intensity and polarization. For this example, we don't, so each of the spectrum fields for beam is the same. Let's plot them for each map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for freq in X.map_tags:\n",
    "    plt.plot(beams['tt'][freq], label=freq)\n",
    "plt.legend()\n",
    "plt.ylabel(r'$B_\\ell$')\n",
    "plt.xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_signal_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check in on our progress of components we've computed. We're trying to build everything to make up our $\\tilde{\\mathcal{C}}^{XY}_{b\\ell}$s, which as a reminder are the following quantity (for TT):\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{\\mathcal{C}}^{XY}_{b\\ell} = \\sum_{\\ell^{\\prime}} K_{\\ell \\ell^{\\prime}}^{X Y} F_{\\ell^{\\prime}}^{X Y} B_{\\ell^{\\prime}}^{2} \\mathcal{C}_{\\ell^{\\prime}}^{X Y (S)} \\chi_{b}\\left(\\ell^{\\prime}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "We have $K_{\\ell, \\ell'}$ and $B_{\\ell}$. For the transfer function calculation, we're going to set $F_\\ell$ to 1 so that we measure $q_b$s as the deviation from a uniform transfer function for our simulations. Binning, $\\chi_b$ has been chosen. All that's left is the full sky signal shape, $\\mathcal{C}_{\\ell'}^{XY (S)}$, loaded with [get_signal_shape()](../api.rst#xfaster.xfaster_class.XFaster.get_signal_shape). \n",
    "\n",
    "For calculating the transfer function, this is just the shape spectrum that went into making our simulations. This spectrum can be specified by setting the [xfaster_run()](../api.rst#xfaster.xfaster_exec.xfaster_run) argument `signal_transfer_spec` to a file containing the spectrum for the signal component. If not provided, the code will look in the maps directory for the signal sims for a file labeled `spec_signal_<signal_type>.dat`. The file is expected to look like a CAMB output file, as demonstrated in `make_example_maps.py`, which writes such a file to the proper location in the signal sims directory.\n",
    "\n",
    "For foreground fitting, this function also applies a frequency-dependent scaling to the input signal shape, using the [scale_dust()](../api.rst#xfaster.spec_tools.scale_dust) function.  The arguments `freq_ref` and `beta_ref` are used to set the reference frequency and spectral index for the scaling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_shape = X.get_signal_shape()\n",
    "print(signal_shape.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will look familiar to you. Note that they are as long as the long dimension of the $K_{\\ell\\ell'}$, which is 2$\\ell_{max}$ + 1. Also note that EB and TB, expected to be zero, are set to a small flat value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell2 = np.arange(1001)\n",
    "lfac2 = ell2 * (ell2 + 1) / (2*np.pi)\n",
    "fig, ax = plt.subplots(2, 3, figsize=(10,7))\n",
    "ax = ax.flatten()\n",
    "for i, (s, spec) in enumerate(signal_shape.items()):\n",
    "    ax[i].plot(lfac2 * spec)\n",
    "    ax[i].set_title(s)\n",
    "    if i in [0,3]:\n",
    "        ax[i].set_ylabel(r'$D_\\ell [\\mu\\mathrm{K}^2]$')\n",
    "    if i in [3,4,5]:\n",
    "        ax[i].set_xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to compute the transfer function, which is computed per map per spectrum per CMB bin in [get_transfer()](../api.rst#xfaster.xfaster_class.XFaster.get_transfer). As a refresher, we're trying to get $q_b^{transfer}$, which is the same as our original expression for $q_b$ in [Equation 17 of the Algorithm page](https://spidercmb.github.io/xfaster/algorithm.html#equation-qb), except now we set noise=0, transfer function=1, and instead of using data for our observed signal, we use the ensemble average of our signal sims:\n",
    "\n",
    "\\begin{equation}\n",
    "q_{b}^{transfer}=\\frac{1}{2} \\sum_{b^{\\prime}} \\mathcal{F}_{b b^{\\prime}}^{-1} \\sum_{\\ell} (2 \\ell+1) g_\\ell^k\\left[ \\left(\\tilde{\\mathbf{C}}_{\\ell}^{-1} \\frac{\\partial \\tilde{\\mathbf{S}}_{\\ell}}{\\partial q_{b^{\\prime}}} \\tilde{\\mathbf{C}}_{\\ell}^{-1}\\right)\\tilde{\\mathbf{C}}_{\\ell}^{signal}\\right]_{kk}\n",
    "\\label{eq:qb_transfer}\n",
    "\\end{equation}\n",
    "\n",
    "The expression for the Fisher matrix does not change, other than the fact that its constituents are the same as detailed above for the transfer function.\n",
    "\n",
    "\n",
    "Within the code, `get_transfer` basically has two steps within the function itself, which it performs per map. \n",
    "\n",
    "1. Load up the $\\tilde{\\mathcal{C}}_{b\\ell}$: \n",
    "```python \n",
    "cbl = self.bin_cl_template(map_tag=m0, transfer=True)\n",
    "```\n",
    "This uses the signal_shape internally that we calculated earlier, `m0` is the map, which is used to select the beam and kernel, and `transfer=True` sets the $F_\\ell$ term to 1.\n",
    "\n",
    "2. Run [fisher_iterate()](../api.rst#xfaster.xfaster_class.XFaster.fisher_iterate).\n",
    "```python\n",
    "ret = self.fisher_iterate(cbl, m0, transfer=True,\n",
    "                          iter_max=iter_max, converge_criteria=converge_criteria,\n",
    "                          save_iters=save_iters, ...)\n",
    "```\n",
    "\n",
    "We'll talk more in the `get_bandpowers` section about the details that happen from here, but broadly, XFaster takes all the inputs we've calculated and a starting $q_b$ guess (1 for all bins), computes the Fisher matrix, plugs that into the $q_b$ equation to get a new $q_b$, and repeats. Once the maximum of |(qb_new-qb)/qb| < converge_criteria, it stops iterating and saves the result.\n",
    "\n",
    "One additional check that `get_transfer` does is to look for transfer function values that are negative. If it finds any, it changes that bin value to the average of the orignal value and the next bin's value. This typically happens due to poor choices of binning or too small a number of signal simulations.\n",
    "\n",
    "Also, Only TT, EE, BB, and TE transfer functions are calculated. EB and TB are computed as\n",
    "```python\n",
    "qb['cmb_eb'] = np.sqrt(np.abs(qb['cmb_ee'] * qb['cmb_bb']))\n",
    "qb['cmb_tb'] = np.sqrt(np.abs(qb['cmb_tt'] * qb['cmb_bb']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = X.get_transfer()\n",
    "print(transfer.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple transfer functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,7), sharey=True)\n",
    "ax = ax.flatten()\n",
    "plot_inds = {'95': 0, '150': 1}\n",
    "for s, spec in transfer.items():\n",
    "    for m, fl in spec.items():\n",
    "        ax[plot_inds[m]].plot(fl, label=s.split('_')[-1])\n",
    "        if 'tt' in s:\n",
    "            ax[plot_inds[m]].set_title(m)\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('bin')\n",
    "for i in [0]:\n",
    "    ax[i].set_ylabel(r'$F_\\ell$')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylim(0,1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the BB transfer function (and the EB/TB terms computed from it) start to diverge at high multipole. This is due to the lack of signal power in our input spectrum combined with the reduction in power of the beam. For this reason, you might choose to use a model spectrum with more BB power in computing your BB transfer functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_masked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the step where we compute the data term using [get_masked_data()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_data). This is once again done just by taking all the pseudo-cross-spectra of all the data maps, using `healpy.map2alm` and `healpy.alm2cls`. This is also the step where the cross spectra of foreground templates is performed, if `template_type` is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_data = X.get_masked_data(data_type=\"raw\")\n",
    "print(cls_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['95:95'], label='95 auto')\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['150:150'], label='150 auto')\n",
    "ax[0].plot(lfac * cls_data['cls_data']['tt']['150:95'], label='95 x 150')\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(r'$D_\\ell [\\mu \\mathrm{K}^2]$')\n",
    "ax[0].set_xlabel(r'$\\ell$')\n",
    "ax[0].set_title('TT')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['95:95'], label='95 auto')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['150:150'], label='150 auto')\n",
    "ax[1].plot(lfac * cls_data['cls_data']['ee']['150:95'], label='95 x 150')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(r'$\\ell$')\n",
    "ax[1].set_title('EE')\n",
    "fig.suptitle('cls_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options for manipulating the constructed data before they are passed to the estimator.\n",
    "\n",
    "* `template_type`, which points to files stored in `templates_<template_type>` for foreground template subtraction\n",
    "* `template_alpha`: not used for null tests.  This is a dictionary of scalar values, keyed by map tag, to scale foreground templates to be subtracted from the data.  The subtraction is done in alm-space for each tag that is included in the dictionary.\n",
    "* `reference_type`, which points to files stored in `reference_<reference_type>` for reference signal subtraction for debiasing null tests.  If `reference_type` is set, then some reference signal is subtracted from each half of a null split.  Typically the reference would be something like _Planck_ half-mission datasets, where the _Planck_ instrument noise between the two sets is uncorrelated, such that the cross spectrum of the two reference signals is independent of _Planck_ instrument noise.\n",
    "* `template_noise_type`, which points to files stored in `templates_noise_<template_noise_type>` for subtracting a correlated noise component from the template terms.  If `template_noise_type` is set, then an ensemble of noise simulations is used to construct an estimate of the instrument noise contribution to the template subtraction and remove it from the data.  Typically this is an ensemble of _Planck_ FFP10 simulations, which by construction introduces a slight correlation in the noise between template halves.  This option accounts for that correlation.\n",
    "* `template_specs`: A list of spectra for which the template subtraction is applied.  By default, this is done for all spectra that the XFaster estimator is computing.  However, when excluding TT/TE signal from the likelihood, it is necessary to avoid subtracting foreground templates from the TT/TE spectra as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, computing things for data is typically the final thing you'll be wanting to do. The first way you'll probably run the code is on simulations to make sure things make sense.  The options for doing this are explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sim options for get_masked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options to [get_masked_data()](../api.rst#xfaster.xfaster_class.XFaster.get_masked_data) that dictate how to build a simulated data set from an ensemble of components on disk.  Note that these options may be passed to this function differently from [xfaster_run()](../api.rst#xfaster.xfaster_exec.xfaster_run).  We'll go through all of them here.\n",
    "\n",
    "First, there are three options that determine whether any simulated dataset is to be used at all in place of data.  If these are all `False`, then the data maps are loaded from disk as usual.\n",
    "\n",
    "* `ensemble_mean`: use `cls_sim` in place of the data spectra. This quantity, computed in [the previous sims step](#get_masked_sims) is the average of the signal+noise sims.\n",
    "* `ensemble_median`: use `cls_med`, the median of the signal+noise sims, in place of the data.\n",
    "* `sim`: if this option is `True`, the remaining options below are used to determine how the simulated dataset is constructed.  In `xfaster_run`, this option is called `sim_data`.\n",
    "\n",
    "The following options control the construction of the dataset when `sim=True`.\n",
    "\n",
    "* `signal_type_sim`/`noise_type_sim`/`foreground_type_sim`/`template_type_sim` -- these are tags corresponding to directories `signal_<signal_type_sim>`, `noise_<noise_type_sim>`, `foreground_<foreground_type_sim>`, `template_<template_type_sim>`. These options are not required to run in `sim_data` mode-- if they are not set, they default to `signal_type_sim=signal_type`, `noise_type_sim=noise_type`, `foreground_type_sim=None` and `template_type_sim=template_type`, as determined in `get_masked_sims()`.\n",
    "* `components`: A list of components to include in the simulation.  These may include `signal`, `noise`, `foreground` or `template`, and require the appropriate `<component>_type_sim` variable to have been set in `get_files()` above.  In `xfaster_run`, this option is called `sim_data_components`.\n",
    "* `index`: A dictionary of indices keyed by component name that determine which file from each ensemble to use to construct the data.  For example, `{\"signal\": 0, \"noise\": 10}` uses difference sim indices for the signal and noise components.  A `default` key sets the sim index to use for any component not included in the dictionary.  If no default is given, then `0` is assumed.  NB: in the `xfaster_run` function, this dictionary is constructed from the arguments `sim_index_default`, `sim_index_signal`, `sim_index_noise` and `sim_index_foreground`.\n",
    "* `r`: If this is not `None`, then the `signal` component of the simulated data is constructed from a linear combination of a scalar CMB term and a tensor CMB term, with the latter scaled by the value of `r`.  This option was used for SPIDER to run the ensemble of simulations needed for the Feldman-Cousins analysis, and was written to allow for constructing many different $r$-input maps in memory. For this option to work, the `signal_type_sim` argument must be set to `\"r\"`, in which case the `get_files()` function searches for an ensemble of scalar sims in the subdirectory `signal_r0` and tensor sims in the subdirectory `signal_r1tens`.  In `xfaster_run`, this option is called `sim_data_r`.\n",
    "* `qb_file`: If this option is not `None`, then it points to a `bandpowers.npz` file on disk, which contains noise residual bandpowers that can be used to scale the noise component of the simulated data.  In `xfaster_run`, this option is called `qb_file_data`.  NB: a similar option, `qb_file_sim`, can be passed to `get_masked_sims()` to instead apply the residual correction to the noise ensemble that goes into the covariance model (e.g. to test for bias or in single-map mode where fitting for noise residuals doesn't work).\n",
    "* `template_alpha_sim`: A dictionary similar to `template_alpha` above that handles the _addition_ of foreground templates to the simulated dataset.  In `xfaster_run`, this dictionary is constructed using the arguments `template_alpha_sim` (a list of floats) and `template_alpha_tags_sim` (a list of map tags for each float).\n",
    "* `save_sim`: If True, the constructed simulation is stored to disk to avoid rebuilding it later.  The filename is constructed as `data_<...>_xcorr.npz` where a set of tags is built from the components that are included in the simulation.  The output `bandpowers.npz` file corresponding to each such simulation includes the same set of tags in the filename.  This file naming scheme allows running multiple simulations in parallel without rerunning intermediate steps or creating IO conflicts on disk.  In `xfaster_run`, this option is called `save_sim_data`.\n",
    " \n",
    "For the example case, we won't use any of these options. They can be super useful for forming expectations for your data outputs, though!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_bandpowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all together!  The function [get_bandpowers()](../api.rst#xfaster.xfaster_class.XFaster.get_bandpowers) works just like [get_transfer()](../api.rst#xfaster.xfaster_class.XFaster.get_transfer), with the transfer function terms no longer set to unity, and instead constructed from the $q_b$s computed by [get_transfer()](../api.rst#xfaster.xfaster_class.XFaster.get_transfer).\n",
    "\n",
    "#### Constructing the model spectrum\n",
    "\n",
    "The first step is to construct the $\\tilde{\\mathcal{C}}_{b\\ell}$'s including all of the additional components in the model. This is done with [bin_cl_template()](../api.rst#xfaster.xfaster_class.XFaster.bin_cl_template)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbl = X.bin_cl_template(map_tag=None, transfer=False, use_precalc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot up each set of components individually.  First, the CMB component, which should look familiar.  Each color represents the $\\tilde{\\mathcal{C}}_{b\\ell}$ for a single bin.  The black lines show the total shape of each component in $\\ell$ if the $q_b$ applied to each bin is set to 1 (ie, our signal model is perfectly correct).  This is what we call the *model spectrum* that we are fitting to.  Notice that the EE and BB mixing terms have very broad bins and are very low amplitude.  This is due to the shape of the $_{-}K_{\\ell\\ell^\\prime}$ kernel as a function of $\\ell$.  These shapes will look different for each map cross, due to differences in each transfer function and beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14,7), sharex=True)\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "comps = ['cmb_tt', 'cmb_te', 'cmb_ee', 'cmb_ee_mix', 'cmb_eb', 'cmb_tb', 'cmb_bb', 'cmb_bb_mix']\n",
    "for ax, comp in zip(axs, comps):\n",
    "    ax.set_title('150 x 150 {}'.format(comp))\n",
    "    cbl1 = cbl[comp]['150:150']\n",
    "    d = cbl1.sum(axis=0)\n",
    "    ax.plot(d * ellfac, 'k')\n",
    "    for d in cbl1:\n",
    "        ax.plot(d * ellfac)\n",
    "for i in [0,4]:\n",
    "    axs[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(4,8):\n",
    "    axs[i].set_xlabel(r'$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model component that we include accounts for residual noise in the auto-spectra.  These $\\tilde{\\mathcal{C}}_{b\\ell}$ terms do not include any transfer functions, beams or mode mixing kernels.  They are derived from the *simulated* noise spectra $\\tilde{N}_\\ell$.  These terms act as corrections to the noise model by adjusting the auto-spectrum noise components to agree with the cross terms.\n",
    "\n",
    "For the example, we fit only for the EE and BB components, and we require them to be the same.  That is, each $q_b^{res,EEBB}$ applies to both $\\tilde{\\mathcal{C}}_{b\\ell}^{EE}$ and $\\tilde{\\mathcal{C}}_{b\\ell}^{BB}$ here. \n",
    "\n",
    "The residual signal model is thus:\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{\\mathbf{S}}_\\ell^{res,ij} = \\delta_{ij}\\,\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\ \n",
    "0 & \\sum_b q_b^{EEBB} \\tilde{\\mathcal{C}}_{b\\ell}^{EE} & 0 \\\\ \n",
    "0 & 0 & \\sum_b q_b^{EEBB} \\tilde{\\mathcal{C}}_{b\\ell}^{BB} \\\\ \n",
    "\\end{bmatrix}_{\\,res,ij}\n",
    "\\label{eq:signal_res}\n",
    "\\end{equation}\n",
    "\n",
    "and the derivatives are\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\tilde{\\mathbf{S}}_\\ell}{\\partial q_b^{res,ij,EEBB}} = \\delta_{ij}\\,\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 \\\\ \n",
    "0 & \\tilde{\\mathcal{C}}_{b\\ell}^{EE} & 0 \\\\ \n",
    "0 & 0 & \\tilde{\\mathcal{C}}_{b\\ell}^{BB} \\\\ \n",
    "\\end{bmatrix}_{\\,res,ij}\n",
    "\\label{eq:signal_res_deriv}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharex=True, figsize=(7,3.5))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "comps = ['res_ee', 'res_bb']\n",
    "for ax, comp in zip(axs, comps):\n",
    "    ax.set_title('150 x 150 {}'.format(comp))\n",
    "    cbl1 = cbl[comp]['150:150']\n",
    "    d = cbl1.sum(axis=0)\n",
    "    ax.plot(d * ellfac, 'k')\n",
    "    for d in cbl1:\n",
    "        ax.plot(d * ellfac)\n",
    "for i in [0]:\n",
    "    axs[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(2):\n",
    "    axs[i].set_xlabel(r'$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add our actual noise simulations to the model.  The residual noise terms discussed above are designed to account for inaccuracies in this model. For both the fiducial noise model and the noise residuals, we assume 0 average noise in cross-spectra, and so only add them to the auto-terms of the model.\n",
    "\n",
    "We often find that the Fisher iterations have trouble converging due to numerical errors that cause the covariance to become singular. To prevent this from happening, we also include a term we call \"conditioning noise\" along the TT/EE/BB diagonals as well.  The conditioning noise is modeled as constant in $\\ell$, where the EE and BB diagonals are set to be `cond_noise` and TT is set to be 10*`cond_noise`. The typical conditioning noise is very small (1e-5 or so), and it is automatically adjusted to be the lowest level possible while still having the algorithm converge. In the final Fisher iteration, the conditioning noise is dropped.\n",
    "\n",
    "To plot up both of these model components, along with all of the terms discussed above, let's call an internal function that computes the model spectrum for us, given the $\\tilde{\\mathcal{C}}_{b\\ell}$ terms and some model parameters $q_b$: [get_model_spectra()](../api.rst#xfaster.xfaster_class.XFaster.get_model_spectra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# construct a dummy qb array to compute input model\n",
    "qb = OrderedDict([(k, np.ones(len(v))) for k, v in X.bin_def.items()])\n",
    "cls_model = X.get_model_spectra(qb, cbl, cls_noise=X.cls_noise, cond_noise=1e-5)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(11,7))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "xname = '150:150'\n",
    "for comp in ['cmb', 'noise', 'res', 'cond', 'total']:\n",
    "    for ax, spec in zip(axs, ['tt', 'ee', 'bb', 'te', 'eb', 'tb']):\n",
    "        stag = '{}_{}'.format(comp, spec)\n",
    "        if stag not in cls_model:\n",
    "            ax.plot(0, 0, label=comp)\n",
    "            continue\n",
    "        if comp in ['res', 'total']:\n",
    "            ax.plot(ellfac * cls_model[stag][xname], label=comp, linestyle='--')\n",
    "        else:\n",
    "            ax.plot(ellfac * cls_model[stag][xname], label=comp)\n",
    "        ax.set_title('150 x 150 {}'.format(spec))\n",
    "        if spec in ['ee', 'bb']:\n",
    "            ax.set_ylim(-0.01, 0.175)\n",
    "axs[0].legend()\n",
    "for i in [0,3]:\n",
    "    axs[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(3,6):\n",
    "    axs[i].set_xlabel(r'$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize=(11,7))\n",
    "axs = axs.ravel()\n",
    "ell = np.arange(501)\n",
    "ellfac = ell * (ell + 1) / 2.0 / np.pi\n",
    "xname = '150:95'\n",
    "for comp in ['cmb', 'noise', 'res', 'cond', 'total']:\n",
    "    for ax, spec in zip(axs, ['tt', 'ee', 'bb', 'te', 'eb', 'tb']):\n",
    "        stag = '{}_{}'.format(comp, spec)\n",
    "        if stag not in cls_model or xname not in cls_model[stag]:\n",
    "            ax.plot(0, 0, label=comp)\n",
    "            continue\n",
    "        ax.plot(ellfac * cls_model[stag][xname], label=comp)\n",
    "        ax.set_title('150 x 95 {}'.format(spec))\n",
    "axs[0].legend()\n",
    "for i in [0,3]:\n",
    "    axs[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(3,6):\n",
    "    axs[i].set_xlabel(r'$\\ell$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that neither conditioning noise nor residual terms are present in the cross-spectra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the Fisher matrix\n",
    "\n",
    "Ok! Now that we have all the pieces in place, all that's left is to do some matrix math and iterate over the equations for [q_b](https://spidercmb.github.io/xfaster/algorithm.html#equation-qb) and the [Fisher matrix](https://spidercmb.github.io/xfaster/algorithm.html#equation-qb) until the results converge.  The two equations are constructed in the function [fisher_calc()](../api.rst#xfaster.xfaster_class.XFaster.fisher_calc), which is called iteratively by [fisher_iterate()](../api.rst#xfaster.xfaster_class.XFaster.fisher_iterate) until convergence is reached.\n",
    "\n",
    "In order to make all the quantities we've computed look like matrices, we have two utility functions, [dict_to_dmat()](../api.rst#xfaster.parse_tools.dict_to_dmat) and [dict_to_dsdqb_mat()](../api.rst#xfaster.parse_tools.dict_to_dsdqb_mat), that convert the dictionaries `Dmat1` (corresponding to $\\mathbf{\\tilde{C}}_\\ell$ in the equations) and `dSdqb_mat1_freq` ($\\partial \\mathbf{\\tilde{S}}_\\ell / \\partial q_b$) into matrices.\n",
    "\n",
    "The `Dmat1` matrix has shape `(3 * num_maps, 3 * num_maps, lmax + 1)` and contains the `total` model terms for each map cross spectrum, ordered as [shown here](https://spidercmb.github.io/xfaster/algorithm.html#equation-dell).  The `dSdqb_mat1_freq` matrix has shape `(3 * num_maps, 3 * num_maps, nbins, lmax + 1)` and includes the CMB, residuals and frequency-corrected foreground components for all the crosses. We then compute the quantity\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\tilde{C}}^{-1} \\frac{\\partial \\mathbf{\\tilde{S}}}{\\partial q_b} \\mathbf{\\tilde{C}}^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "using the following code:\n",
    "\n",
    "```python\n",
    "Dinv = np.linalg.inv(Dmat1.swapaxes(0, -1)).swapaxes(0, -1)\n",
    "eye = np.eye(len(gmat))\n",
    "mat1 = np.einsum('ij...,jk...->ik...', eye, Dinv)\n",
    "mat2 = np.einsum('klm...,ln...->knm...', dSdqb_mat1_freq, Dinv)\n",
    "mat = np.einsum('ik...,knm...->inm...', mat1, mat2)\n",
    "```\n",
    "\n",
    "The first line computes the inverse of $D$, ell-by-ell along the first two dimensions.  The next two lines are necessary due to some quirk of memory access in python; this is just multiplying the first two dimensions of `Dmat1` by the identity matrix.  The last two lines do the matrix multiplication along the first two dimensions of each of the matrices.\n",
    "\n",
    "Now, we apply the $\\mathbf{g}_\\ell$ mode-counting factor, and at the same time take the trace and sum over ell, computing everything needed for $q_b$ except $\\Sigma_b \\mathcal{F}_{b b^{\\prime}}$:\n",
    "```python\n",
    "qb_vec = np.einsum(\"iil,ijkl,jil->k\", gmat, mat, Dmat_obs) / 2.0\n",
    "```\n",
    "The Fisher matrix is:\n",
    "```python\n",
    "fisher = np.einsum(\"iil,ijkl,jiml->km\", gmat, mat, dSdqb_mat1_freq) / 2\n",
    "```\n",
    "\n",
    "Finally, we get our updated estimate of $q_b$ and its covaraince, the inverse Fisher matrix, and then convert the former array into a readable dictionary:\n",
    "```python\n",
    "qb_vec = np.linalg.solve(fisher, qb_vec)\n",
    "inv_fish = np.linalg.solve(fisher, np.eye(len(qb_vec)))\n",
    "qb_vec = pt.arr_to_dict(qb_vec, qb)\n",
    "```\n",
    "\n",
    "With each iteration, we compare the new `qb_vec` quantity to the previous one, until the maximum fractional change in any element of the array is less than the convergence criterion (0.005 is typical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing final bandpowers\n",
    "\n",
    "To construct bandpowers, we need to convert the $q_b$ parameters to spectrum bandpowers. The function that handles this is [do_qb2cb()](../api.rst#xfaster.xfaster_class.XFaster.do_qb2cb) This is done by first constructing window functions for each $q_b$ parameter (using [fisher_calc()](../api.rst#xfaster.xfaster_class.XFaster.fisher_calc) with the option `windows=True`), then using that to build a matrix that rotates $q_b$ into bandpowers.  For this example, the quantity we want in the end should be in units of $\\mathcal{D}_\\ell = \\ell (\\ell + 1) C_\\ell / 2\\pi$. You can also return bandpowers in units of $C_\\ell$ using `return_cls=True`, which will change the rotation matrix.  Explicitly, we have for the $\\mathcal{D}_b$ bandpowers:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{D}^{XY}_b = \\sum_B q^{XY}_B \\frac{\\partial\\langle \\mathcal{D}^{XY}_b\\rangle}{\\partial q^{XY}_B} =\n",
    "\\sum_B q^{XY}_B \\frac{\\sum_\\ell \\mathcal{N}_\\ell W^{XY(q)}_{b\\ell} \\chi^{XY}_{B \\ell} \\mathcal{D}^{XY(S)}_\\ell} {\\sum_\\ell \\mathcal{N}_\\ell W^{XY(q)}_{b\\ell} }\\,,\n",
    "\\end{equation}\n",
    "\n",
    "where the normalization function is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{N}_\\ell = \\frac{1}{2}\\frac{(2\\ell + 1)}{\\ell (\\ell + 1)}\\,,\n",
    "\\end{equation}\n",
    "\n",
    "and the matrix of derivatives is block-diagonal in the spectrum component $XY$. Similarly, the errors on each bandpower are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta\\mathcal{D}_b = \\left[\\sum_{BB^\\prime} \\mathcal{F}^{-1}_{BB^\\prime} \\frac{\\partial\\langle \\mathcal{D}_b\\rangle}{\\partial q_B} \\frac{\\partial\\langle \\mathcal{D}_{b}\\rangle}{\\partial q_{B^\\prime}}\\right]^{1/2}\\,,\n",
    "\\end{equation}\n",
    "\n",
    "and the window functions for each $\\mathcal{D}_b$ are:\n",
    "\n",
    "\\begin{equation}\n",
    "W_{b\\ell}^{XY(\\mathcal{D})} = \\sum_B W_{B\\ell}^{XY(q)} \\frac{\\partial\\langle \\mathcal{D}^{XY}_b\\rangle}{\\partial q^{XY}_B} \\,,\n",
    "\\end{equation}\n",
    "\n",
    "with normalization $\\sum_\\ell \\mathcal{N}_\\ell W_{b\\ell}^{(\\mathcal{D})} = 1$.  The bandpowers, errors, $q_b$ window functions and bandpower window functions are all stored in the bandpowers output file.  More details on the bandpower window functions can be found in Section 2.5 of the [XFaster paper](https://arxiv.org/abs/2104.01172)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll just run the function that wraps up all these internal functions, [get_bandpowers()](../api.rst#xfaster.xfaster_class.XFaster.get_bandpowers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = X.get_bandpowers(converge_criteria=0.005, iter_max=200, save_iters=True, cond_noise=1e-5, cond_criteria=5e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot below, we'll plot up the maximum fractional change in $q_b$ with iteration. This information is printed in the logs, but it's helpful to visualize on a plot. You can see it bounce around early on before settling down and ultimately stopping once it gets to the desginated criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "iters = sorted(glob.glob('../../example/outputs_example/95x150/bandpowers_iter*'))\n",
    "### Figure for seeing how convergence looks in fqb\n",
    "fig_fqb, ax_fqb = plt.subplots()\n",
    "ax_fqb.axhline(0.005, label='convergence criterion', color='C1')\n",
    "ax_fqb.set_title('Max fractional change in qb vs iter')\n",
    "ax_fqb.set_ylabel('Maximum absolute fqb')\n",
    "ax_fqb.set_xlabel('Iteration')\n",
    "fqb = np.zeros(len(iters))\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    fqb[i] = np.max(np.abs(b['fqb']))\n",
    "ax_fqb.plot(fqb, marker='o')\n",
    "ax_fqb.legend()\n",
    "ax_fqb.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how the total model (summing up the $q_b\\mathcal{C}_{b\\ell}$ terms for every component) to see how it converges to fit the data. Within a few iterations, it's quite close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure for looking at how sum(qbCbl) changes with iteration to match data\n",
    "figtmp = plt.figure()\n",
    "tmpplot = plt.imshow(np.zeros((2,2)), cmap='viridis',vmin=0, vmax=len(iters))\n",
    "plt.close(figtmp)\n",
    "fig_dat, ax_dat = plt.subplots(2,3, figsize=(15,10))\n",
    "ax_dat = ax_dat.flatten()\n",
    "specs = ['tt', 'ee', 'bb', 'te', 'tb', 'eb']\n",
    "colors = colormaps['viridis'].resampled(len(iters)).colors\n",
    "for s, spec in enumerate(specs):\n",
    "    ax_dat[s].set_title(spec)\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    for s, spec in enumerate(specs):\n",
    "        if i == 0:\n",
    "            # data cls don't change with iter- plot once.\n",
    "            ax_dat[s].plot(b['cls_obs'][spec]['150:95'] * lfac, color='gray', label='data')\n",
    "        ax_dat[s].plot(b['cls_model']['total_'+spec]['150:95'] * lfac, color=colors[i])\n",
    "for i in [0, 3]:\n",
    "    ax_dat[i].set_ylabel(r'$D_\\ell$')\n",
    "for i in range(3,5):\n",
    "    ax_dat[i].set_xlabel(r'$\\ell$')\n",
    "ax_dat[0].legend()\n",
    "fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)\n",
    "\n",
    "fig_dat.suptitle(r'95$\\times$150 GHz total power fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at just the $q_b$ values for each of the different component and see how they converge as a function of iteration and bin. The lowest bins tend to have the biggest moves, but for all components, everything gets close to its final value within a handful of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Figure for looking at how qb for each bandpower changes with iteration\n",
    "figtmp = plt.figure()\n",
    "tmpplot = plt.imshow(np.zeros((2,2)), cmap='viridis',vmin=0, vmax=len(iters))\n",
    "plt.close(figtmp)\n",
    "specs = ['tt', 'ee', 'bb', 'te', 'tb', 'eb']\n",
    "colors = colormaps['viridis'].resampled(len(iters)).colors\n",
    "scatter = 1. / 50.\n",
    "for comp in ['cmb']:\n",
    "    fig_dat, ax_dat = plt.subplots(3,2, figsize=(20,15))\n",
    "    fig_dat.suptitle(comp+r' $q_b$ vs. iteration')\n",
    "    ax_dat = ax_dat.flatten()\n",
    "    for s, spec in enumerate(specs):\n",
    "        ax_dat[s].set_title(spec)\n",
    "        ax_dat[s].axhline(1, color='gray', alpha=0.7)\n",
    "    for i, bp0 in enumerate(iters):\n",
    "        b = xf.load_and_parse(bp0)\n",
    "        for s, spec in enumerate(specs):\n",
    "            ax_dat[s].scatter(np.arange(20) + scatter * i, \n",
    "                              b['qb'][comp+'_'+spec], color=colors[i], s=4)\n",
    "    for i in [0, 2, 4]:\n",
    "        ax_dat[i].set_ylabel(r'$q_b$')\n",
    "    for i in range(4,5):\n",
    "        ax_dat[i].set_xlabel('bin')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.01)\n",
    "    fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                     orientation='horizontal', shrink=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the noise residuals that were fit. In the script where we make the example maps, we made the \"data\" maps have 15% less noise in them than the those used for the noise model. So, we should expect the total noise, $(1+n_b)\\left<N\\right>$, to be $0.85^2\\left<N\\right>$, where the square comes because we're fitting in the power spectrum. So, $n_b$s should converge to about -0.28. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot residuals\n",
    "fig_dat, ax_dat = plt.subplots(1,2, figsize=(10,8))\n",
    "fig_dat.suptitle(r'res $q_b$ vs. iteration')\n",
    "ax_dat = ax_dat.flatten()\n",
    "maps = [x for x in bp['qb'] if 'res' in x]\n",
    "for s, m0 in enumerate(maps):\n",
    "    ax_dat[s].set_title(m0)\n",
    "    ax_dat[s].axhline(0, color='gray', alpha=0.7)\n",
    "    ax_dat[s].set_ylim(-2,2)\n",
    "for i, bp0 in enumerate(iters):\n",
    "    b = xf.load_and_parse(bp0)\n",
    "    for s, m0 in enumerate(maps):\n",
    "        ax_dat[s].scatter(np.arange(5) + scatter * i, \n",
    "                          b['qb'][m0], color=colors[i], s=4)\n",
    "for i in [0]:\n",
    "    ax_dat[i].set_ylabel(r'$q_b$')\n",
    "for i in range(2):\n",
    "    ax_dat[i].set_xlabel('bin')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.01)\n",
    "fig_dat.colorbar(tmpplot, label='Iteration', ax=ax_dat.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything has converged, let's plot up what the final bandpowers and error bars look like. XFaster saves the binned bandpowers as $D_\\ell$s by default, though they are labeled `cb`. The error bars are in `dcb`, and those are also computed without sample variance in `dcb_nosampvar`. Covariance is in `cov`, and it also has a no sample variance version, `cov_nosampvar`.\n",
    "\n",
    "To calculate error bars and covariances without sample variance, XFaster just does one final calculation of the Fisher matrix (after everything has converged), with all the $q_b$s set to a very small number, thereby nulling out the signal. The error bars and covariance without sample variance come from that Fisher matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in ['cmb']:\n",
    "    fig, ax = plt.subplots(3,2, figsize=(20,15))\n",
    "    ax = ax.flatten()\n",
    "    fig.suptitle('{} final estimated bandpowers'.format(comp))\n",
    "    for s, spec in enumerate(specs):\n",
    "        sn = '{}_{}'.format(comp, spec)\n",
    "        ax[s].set_title(spec)\n",
    "        ax[s].plot(lfac * signal_shape[sn][:501], 'k-', label='Model')     \n",
    "        ax[s].errorbar(bp['ellb'][sn], bp['cb'][sn], bp['dcb'][sn], label='sampvar') \n",
    "        ax[s].errorbar(bp['ellb'][sn]+2, bp['cb'][sn], bp['dcb_nosampvar'][sn], label='no sampvar')\n",
    "    ax[0].legend()\n",
    "    for i in [0, 2, 4]:\n",
    "        ax[i].set_ylabel(r'$D_\\ell$')\n",
    "    for i in [4,5]:\n",
    "        ax[i].set_xlabel(r'$\\ell$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error bars are just the diagonal of the covariance matrix. Let's look at the covariance matrix with and without sample variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "norm = LogNorm(vmin=10, vmax=1e4)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,10))\n",
    "fig.suptitle('Covariance')\n",
    "p = ax[0].imshow(np.abs(bp['cov']), norm=norm)\n",
    "ax[0].set_title('With sample variance')\n",
    "ax[1].imshow(np.abs(bp['cov_nosampvar']), norm=norm)\n",
    "fig_dat.colorbar(p, label='Covariance', ax=ax.ravel().tolist(), \n",
    "                 orientation='horizontal', shrink=0.5)\n",
    "ax[1].set_title('Without sample variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 120 x 120 bin matrix, with each of the 20 CMB bins for each spectrum in order (TT, EE, BB, TE, EB, TB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute parameter likelihoods with [get_likelihood()](../api.rst#xfaster.xfaster_class.XFaster.get_likelihood). All of the things we've constructed so far are used, except instead of parameterizing the model with $q_b$ bandpower deviations, we set those to 1, and then make the model a function of cosmological parameters. For the example, we will just use $r$ as our parameter. We then compute the likelihood for the data for each step in a Monte Carlo sampler, where we just vary $r$. For this example, since we're only varying one paramter, we'll do a brute force search: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike = X.get_likelihood(qb=bp['qb'], inv_fish=bp['inv_fish'], mcmc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(loglike[0], np.exp(loglike[1]-loglike[1].max()))\n",
    "plt.ylabel('Likelihood')\n",
    "plt.xlabel(r'$r$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we recover something pretty close to 1, our input $r$ value for the example. If we ran this for many signal+noise sims, we should get precisely 1 in the average. \n",
    "\n",
    "If you instead are using mcmc=True, the likelihoods file written to disk will have a field called \"samples\". Histogramming that up, or using a program like `getdist`, especially helpful for multiple parameters, will give you the posteriors for your various parameters.\n",
    "\n",
    "The likelihoods function sets the CMB qb values to 1 and all others (esp., residuals) to their maximum likelihood values. To instead include these parameters in your fit, you set the `prior` arguments. So:\n",
    "\n",
    "* `r_prior`: set to [0, 'inf'] to inclue $r$ in the fit (or ['-inf', 'inf'] to impose no physical prior)\n",
    "* `alpha_prior`: same as `r_prior`-- set to None to not fit for alpha template scalings.\n",
    "* `res_prior`: same as previous-- will vary all $n_b$ parameters as part of the model\n",
    "* `beam_prior`: this is different! To account for beam uncertainty, set this to [0, 1], where the first parameter is the Gaussian mean, and the second is the number of standard deviations to use as the width. Here, you must have set the `beam_error_product` in your config file to a dictionary containing the one-sigma error on the beam shape per ell, and then that envelope is varied according to a Gaussian with each step to marginalize over the beam uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That wraps up the example!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.35px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
